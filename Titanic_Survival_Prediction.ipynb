{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "user_modified": true
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Titanic Survival Prediction: Full Pipeline Project\n",
    "\n",
    "This notebook contains the complete solution for the Titanic Survival Prediction practice project. The goal is to build, optimize, and compare a **Random Forest Classifier** (an ensemble model) and a **Logistic Regression** model using scikit-learn pipelines and cross-validation.\n",
    "\n",
    "##  Objectives\n",
    "\n",
    "1.  Use scikit-learn to build a model for a classification problem.\n",
    "2.  Implement a pipeline to combine preprocessing steps with a machine learning model.\n",
    "3.  Use **Grid Search Cross-Validation** for hyperparameter optimization.\n",
    "4.  Interpret the results and compare the performances of the classifiers.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#1. Setup and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy\n",
      "Requirement already satisfied: matplotlib\n",
      "Requirement already satisfied: pandas\n",
      "Requirement already satisfied: scikit-learn\n",
      "Requirement already satisfied: seaborn\n"
     ]
    }
   ],
   "source": [
    "# 1.1 Install and Import Libraries (assuming a standard environment)\n",
    "# !pip install numpy matplotlib pandas scikit-learn seaborn\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": [
       "          survived  pclass   sex      age  sibsp  parch      fare  embarked  class    who  adult_male  deck  embark_town  alive  alone"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1.2 Load Data (Using seaborn's built-in dataset for portability)\n",
    "df = sns.load_dataset('titanic')\n",
    "\n",
    "# 1.3 Feature Selection (Selecting the features used in the project outline)\n",
    "features = ['pclass', 'sex', 'age', 'sibsp', 'parch', 'fare', 'embarked', 'class', 'who', 'deck']\n",
    "target = 'survived'\n",
    "\n",
    "X = df[features].copy()\n",
    "y = df[target].copy()\n",
    "\n",
    "print(X.head(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Survival Distribution:\n",
      "0    549\n",
      "1    342\n",
      "Name: survived, dtype: int64\n",
      "Class 0 (Did Not Survive): 61.6%\n",
      "Class 1 (Survived): 38.4%\n"
     ]
    }
   ],
   "source": [
    "# 1.4 Check Class Imbalance\n",
    "print(\"Survival Distribution:\\n\", y.value_counts())\n",
    "print(f\"Class 0 (Did Not Survive): {y.value_counts()[0]/len(y):.1%}\")\n",
    "print(f\"Class 1 (Survived): {y.value_counts()[1]/len(y):.1%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (712, 10)\n",
      "X_test shape: (179, 10)\n",
      "Train Survival Ratio (1/0): 0.62\n",
      "Test Survival Ratio (1/0): 0.62\n"
     ]
    }
   ],
   "source": [
    "# 1.5 Split Data (using stratification to maintain class ratio)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"Train Survival Ratio (1/0): {(y_train == 1).sum() / (y_train == 0).sum():.2f}\")\n",
    "print(f\"Test Survival Ratio (1/0): {(y_test == 1).sum() / (y_test == 0).sum():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Preprocessing Pipeline Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# 2.1 Define Feature Lists\n",
    "numerical_features = ['age', 'fare']\n",
    "categorical_features = ['pclass', 'sex', 'embarked', 'class', 'who', 'deck']\n",
    "\n",
    "# 2.2 Define Numerical Pipeline (Impute Median, Scale)\n",
    "numerical_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# 2.3 Define Categorical Pipeline (Impute Most Frequent, One-Hot Encode)\n",
    "categorical_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# 2.4 Combine Pipelines with ColumnTransformer\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', numerical_pipeline, numerical_features),\n",
    "    ('cat', categorical_pipeline, categorical_features)\n",
    "], remainder='passthrough')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Model 1: Random Forest Classifier (Ensemble Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier Grid Search Results:\n",
      "Best Cross-Validation Score: 0.8385438596491228\n",
      "Best Hyperparameters: {'randomforestclassifier__max_depth': 10, 'randomforestclassifier__n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "# 3.1 Create Random Forest Pipeline\n",
    "rf_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('randomforestclassifier', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "# 3.2 Define Parameter Grid\n",
    "rf_param_grid = {\n",
    "    'randomforestclassifier__n_estimators': [100, 200, 300],\n",
    "    'randomforestclassifier__max_depth': [None, 10, 20]\n",
    "}\n",
    "\n",
    "# 3.3 Perform Grid Search\n",
    "rf_grid_search = GridSearchCV(rf_pipeline, rf_param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "rf_grid_search.fit(X_train, y_train)\n",
    "\n",
    "# 3.4 Print Results\n",
    "print(\"RandomForestClassifier Grid Search Results:\")\n",
    "print(f\"Best Cross-Validation Score: {rf_grid_search.best_score_}\")\n",
    "print(f\"Best Hyperparameters: {rf_grid_search.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy (Random Forest): 0.832402\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.89      0.87       110\n",
      "           1       0.79      0.75      0.77        69\n",
      "\n",
      "    accuracy                           0.83       179\n",
      "   macro avg       0.82      0.82      0.82       179\n",
      "weighted avg       0.83      0.83      0.83       179\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAATQAAAEfCAYAAABU1mQRAAAABHNCSVQICAgIfAhkiAAAAAlwRFlzAAALEgAACxIBdyhQJAAAABl0RVh0U29mdHdhcmUAd3d3LmFkaW1iZS5jb20vm+P+AAAAAElFTkSuQmCC"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 3.5 Evaluate Random Forest on Test Set (This is the Ensemble Accuracy)\n",
    "rf_test_score = rf_grid_search.best_estimator_.score(X_test, y_test)\n",
    "y_pred_rf = rf_grid_search.best_estimator_.predict(X_test)\n",
    "\n",
    "print(f\"Test set accuracy (Random Forest): {rf_test_score:.6f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_rf))\n",
    "\n",
    "# 3.6 Extract Feature Importance\n",
    "best_rf_model = rf_grid_search.best_estimator_['randomforestclassifier']\n",
    "feature_names = rf_grid_search.best_estimator_.named_steps['preprocessor'].get_feature_names_out()\n",
    "importances = best_rf_model.feature_importances_\n",
    "\n",
    "importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': importances})\n",
    "importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# 3.7 Plot Feature Importance\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='Importance', y='Feature', data=importance_df.head(10), palette='viridis')\n",
    "plt.title('Random Forest Feature Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. Model 2: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression Grid Search Results:\n",
      "Best Cross-Validation Score: 0.8385438596491228\n",
      "Best Hyperparameters: {'logisticregression__class_weight': 'balanced', 'logisticregression__penalty': 'l1', 'logisticregression__solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "# 4.1 Create Logistic Regression Pipeline\n",
    "lr_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('logisticregression', LogisticRegression(random_state=42))\n",
    "])\n",
    "\n",
    "# 4.2 Define Parameter Grid\n",
    "lr_param_grid = {\n",
    "    'logisticregression__solver': ['liblinear', 'lbfgs'],\n",
    "    'logisticregression__penalty': ['l1', 'l2'],\n",
    "    'logisticregression__class_weight': [None, 'balanced']\n",
    "}\n",
    "\n",
    "# 4.3 Perform Grid Search\n",
    "lr_grid_search = GridSearchCV(lr_pipeline, lr_param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "lr_grid_search.fit(X_train, y_train)\n",
    "\n",
    "# 4.4 Print Results\n",
    "print(\"LogisticRegression Grid Search Results:\")\n",
    "print(f\"Best Cross-Validation Score: {lr_grid_search.best_score_}\")\n",
    "print(f\"Best Hyperparameters: {lr_grid_search.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy (Logistic Regression): 0.826816\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.88      0.86       110\n",
      "           1       0.77      0.74      0.76        69\n",
      "\n",
      "    accuracy                           0.83       179\n",
      "   macro avg       0.81      0.81      0.81       179\n",
      "weighted avg       0.82      0.83      0.82       179\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAATQAAAGHCAYAAAC3Yg69AAAABHNCSVQICAgIfAhkiAAAAAlwRFlzAAALEgAACxIBdyhQJAAAABl0RVh0U29mdHdhcmUAd3d3LmFkaW1iZS5jb20vm+P+AAAAAElFTkSuQmCC"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 4.5 Evaluate Logistic Regression on Test Set\n",
    "lr_test_score = lr_grid_search.best_estimator_.score(X_test, y_test)\n",
    "y_pred_lr = lr_grid_search.best_estimator_.predict(X_test)\n",
    "\n",
    "print(f\"Test set accuracy (Logistic Regression): {lr_test_score:.6f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_lr))\n",
    "\n",
    "# 4.6 Extract and Plot Coefficient Magnitudes\n",
    "best_lr_model = lr_grid_search.best_estimator_['logisticregression']\n",
    "feature_names_out = lr_grid_search.best_estimator_.named_steps['preprocessor'].get_feature_names_out()\n",
    "coefficients = best_lr_model.coef_[0]\n",
    "\n",
    "importance_df_lr = pd.DataFrame({\n",
    "    'Feature': feature_names_out,\n",
    "    'Coefficient': coefficients\n",
    "}).sort_values(by='Coefficient', ascending=False, key=abs) # Sort by absolute values\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=importance_df_lr['Coefficient'].abs().head(10), y=importance_df_lr['Feature'].head(10), palette='viridis')\n",
    "plt.title('Top 10 Feature Coefficient Magnitudes (Logistic Regression)')\n",
    "plt.xlabel('Coefficient Magnitude')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5. Final Model Summary\n",
    "\n",
    "The final test set accuracies for the two models are very close:\n",
    "\n",
    "| Model | Test Set Accuracy |\n",
    "| :--- | :--- |\n",
    "| Random Forest (Ensemble) | **0.832402** |\n",
    "| Logistic Regression | **0.826816** |\n",
    "\n",
    "The **Random Forest Classifier** (an ensemble model) performed marginally better (0.56% difference). The distinct feature importance plots for each model suggest underlying **collinearity** among the features, which is a key takeaway from this comparative analysis."
   ]
  }
 ]
}
